{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import os\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["d:\\ClonedRepositories\\predict-tourist-attraction\\pre_processing\n"]}],"source":["# print current directory\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"ename":"MemoryError","evalue":"Unable to allocate 12.7 GiB for an array with shape (8511, 200704) and data type object","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32md:\\ClonedRepositories\\predict-tourist-attraction\\pre_processing\\images_to_dataset.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ClonedRepositories/predict-tourist-attraction/pre_processing/images_to_dataset.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         labels\u001b[39m.\u001b[39mappend(label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ClonedRepositories/predict-tourist-attraction/pre_processing/images_to_dataset.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Convert to a dataframe and export to CSV\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/ClonedRepositories/predict-tourist-attraction/pre_processing/images_to_dataset.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ClonedRepositories/predict-tourist-attraction/pre_processing/images_to_dataset.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m labels\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ClonedRepositories/predict-tourist-attraction/pre_processing/images_to_dataset.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mimage_data.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n","File \u001b[1;32mc:\\Users\\Zahil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:745\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    744\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 745\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    746\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    747\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    748\u001b[0m         data,\n\u001b[0;32m    749\u001b[0m         columns,\n\u001b[0;32m    750\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    751\u001b[0m         dtype,\n\u001b[0;32m    752\u001b[0m     )\n\u001b[0;32m    753\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    754\u001b[0m         arrays,\n\u001b[0;32m    755\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    758\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    759\u001b[0m     )\n\u001b[0;32m    760\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\Zahil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:510\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[1;32m--> 510\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    511\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    513\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\Zahil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:873\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m     \u001b[39m# last ditch effort\u001b[39;00m\n\u001b[0;32m    872\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[1;32m--> 873\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m    875\u001b[0m content, columns \u001b[39m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[0;32m    876\u001b[0m \u001b[39mreturn\u001b[39;00m content, columns\n","File \u001b[1;32mc:\\Users\\Zahil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:883\u001b[0m, in \u001b[0;36m_list_to_arrays\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_list_to_arrays\u001b[39m(data: \u001b[39mlist\u001b[39m[\u001b[39mtuple\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m    880\u001b[0m     \u001b[39m# Returned np.ndarray has ndim = 2\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39m# Note: we already check len(data) > 0 before getting hre\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 883\u001b[0m         content \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mto_object_array_tuples(data)\n\u001b[0;32m    884\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    885\u001b[0m         \u001b[39m# list of lists\u001b[39;00m\n\u001b[0;32m    886\u001b[0m         content \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mto_object_array(data)\n","File \u001b[1;32mc:\\Users\\Zahil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:3023\u001b[0m, in \u001b[0;36mpandas._libs.lib.to_object_array_tuples\u001b[1;34m()\u001b[0m\n","\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 12.7 GiB for an array with shape (8511, 200704) and data type object"]}],"source":["\n","# data_path = '../dataset/data'\n","# img_size = (224, 224)  # Change this to the desired size of your images\n","\n","# # Load the data\n","# data = []\n","# labels = []\n","# for subdir, _, files in os.walk(data_path):\n","#     for file in files:\n","#         label = os.path.basename(subdir)\n","#         img_path = os.path.join(subdir, file)\n","#         img = Image.open(img_path).resize(img_size)\n","#         img = np.array(img)\n","#         data.append(img.flatten())\n","#         labels.append(label)\n","\n","# # Convert to a dataframe and export to CSV\n","# df = pd.DataFrame(data)\n","# df['label'] = labels\n","# df.to_csv('image_data.csv', index=False)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 8490 files belonging to 20 classes.\n","Found 8490 files belonging to 20 classes.\n"]}],"source":["directory = \"../dataset/data/\"\n","\n","batch_size = 32\n","img_height = 224\n","img_width = 224\n","\n","ds = tf.keras.utils.image_dataset_from_directory(\n","    directory,\n","    validation_split=None,\n","    subset=None,\n","    seed=None,\n","    shuffle=True,\n","    image_size=(img_height, img_width),\n","    batch_size=batch_size)\n","\n","tf.data.Dataset.save(ds, \"tourist_attraction_dataset_224\")\n","\n","# batch_size = 32\n","# img_height = 128\n","# img_width = 128\n","\n","# ds = tf.keras.utils.image_dataset_from_directory(\n","#     directory,\n","#     validation_split=None,\n","#     subset=None,\n","#     seed=None,\n","#     shuffle=True,\n","#     image_size=(img_height, img_width),\n","#     batch_size=batch_size)\n","\n","# tf.data.Dataset.save(ds, \"tourist_attraction_dataset_128\")\n","\n","# batch_size = 32\n","# img_height = 64\n","# img_width = 64\n","\n","# ds = tf.keras.utils.image_dataset_from_directory(\n","#     directory,\n","#     validation_split=None,\n","#     subset=None,\n","#     seed=None,\n","#     shuffle=True,\n","#     image_size=(img_height, img_width),\n","#     batch_size=batch_size)\n","\n","# tf.data.Dataset.save(ds, \"tourist_attraction_dataset_64\")\n","\n","batch_size = 32\n","img_height = 32\n","img_width = 32\n","\n","ds = tf.keras.utils.image_dataset_from_directory(\n","    directory,\n","    validation_split=None,\n","    subset=None,\n","    seed=None,\n","    shuffle=True,\n","    image_size=(img_height, img_width),\n","    batch_size=batch_size)\n","\n","tf.data.Dataset.save(ds, \"tourist_attraction_dataset_32\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"23479fdb4eb39c7244a8681c3fcbaa211462ba4fe322f69ce3d54ceea35e9ccf"}}},"nbformat":4,"nbformat_minor":2}
